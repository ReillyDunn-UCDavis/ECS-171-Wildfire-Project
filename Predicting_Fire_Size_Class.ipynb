{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "IEhzv9xtAL7-"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import classification_report, confusion_matrix, multilabel_confusion_matrix\n",
        "from sklearn.metrics import mean_squared_error, accuracy_score, precision_score, recall_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "['Latitude', 'Longitude']",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3508\\3077548972.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtargetFeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"FIRE_SIZE_CLASS\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0minputFeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"FIRE_YEAR\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"DISCOVERY_DOY\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Latitude\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Longitude\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"DURATION_HOURS\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Precipitation_In_Month\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Avg_Temp_In_Month\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# Drop NaN values from columns in targetFeatures and inputFeatures\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtargetFeatures\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0minputFeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minputFeatures\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtargetFeatures\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\owenh\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, axis, how, thresh, subset, inplace, ignore_index)\u001b[0m\n\u001b[0;32m   6403\u001b[0m             \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0magg_axis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6404\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer_for\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6405\u001b[0m             \u001b[0mcheck\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindices\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6406\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mcheck\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6407\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcheck\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6408\u001b[0m             \u001b[0magg_obj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0magg_axis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6409\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6410\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mthresh\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mno_default\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mKeyError\u001b[0m: ['Latitude', 'Longitude']"
          ]
        }
      ],
      "source": [
        "filename = \"Updated Fire Data - First 10k.csv\"\n",
        "dataset = pd.read_csv(filename)\n",
        "\n",
        "targetFeatures = [\"FIRE_SIZE_CLASS\"]\n",
        "inputFeatures = [\"FIRE_YEAR\", \"DISCOVERY_DOY\", \"LATITUDE\", \"LONGITUDE\", \"DURATION_HOURS\", \"Precipitation_In_Month\", \"Avg_Temp_In_Month\"]\n",
        "\n",
        "# Drop NaN values from columns in targetFeatures and inputFeatures\n",
        "dataset.dropna(subset=targetFeatures + inputFeatures, inplace=True)\n",
        "\n",
        "X = dataset[inputFeatures]\n",
        "y = dataset[targetFeatures]\n",
        "\n",
        "# normalize data\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "X_rescaled = scaler.fit_transform(X)\n",
        "X = pd.DataFrame(data = X_rescaled, columns = X.columns)\n",
        "\n",
        "categories = [['A', 'B', 'C', 'D', 'E', 'F', 'G']]\n",
        "encoder = OneHotEncoder(categories=categories, sparse=False)\n",
        "y = encoder.fit_transform(y.values.reshape(-1,1))\n",
        "\n",
        "print(\"Pre-processed data :\")\n",
        "print(X)\n",
        "\n",
        "print(\"Pre-processed class :\")\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_train, data_test, class_train, class_test = train_test_split(X, y, test_size=0.3)\n",
        "\n",
        "mlp = MLPClassifier(solver = 'sgd', random_state = 42, activation = 'logistic', learning_rate_init = 0.2, batch_size = 10, hidden_layer_sizes = (10, 10), max_iter = 500)\n",
        "\n",
        "mlp.fit(data_train, class_train)\n",
        "\n",
        "pred = mlp.predict(data_test)\n",
        "pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Accuracy : \", accuracy_score(class_test, pred))\n",
        "print(\"Mean Square Error : \", mean_squared_error(class_test, pred))\n",
        "\n",
        "print(\"Confusion Matrix for each label : \")\n",
        "#print(multilabel_confusion_matrix(class_test, pred))\n",
        "\n",
        "classNum = 0\n",
        "for matrix in multilabel_confusion_matrix(class_test, pred):\n",
        "  print(f\"Class: {categories[0][classNum]}\")\n",
        "  classNum += 1\n",
        "\n",
        "  tn, fp, fn, tp = matrix.ravel()\n",
        "  print(f\"         Actual Positive | Actual Negative\")\n",
        "  print(f\"-------------------|-----|----------------\")\n",
        "  print(f\"Predicted Positive | {str(tp).rjust(3)} | {str(fp).rjust(3)}\")\n",
        "  print(f\"-------------------|-----|----------------\")\n",
        "  print(f\"Predicted Negative | {str(fn).rjust(3)} | {str(tn).rjust(3)}\")\n",
        "  print(f\"TP: {tp}, FP: {fp}, FN: {fn}, TN: {tn}\\n\")\n",
        "\n",
        "print(\"Classification Report : \")\n",
        "print(classification_report(class_test, pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Original Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 168,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NdNa26r_NRn",
        "outputId": "0122d14d-67a5-466a-8ba6-132b215bc36b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pre-processed data :\n",
            "    FIRE_YEAR  DISCOVERY_DOY  DISCOVERY_TIME  Precipitation_In_Month  \\\n",
            "0         1.0       0.095975        0.588101                0.666055   \n",
            "1         0.0       0.405573        0.379863                0.003670   \n",
            "2         0.0       0.464396        0.872311                0.003670   \n",
            "3         0.0       0.551084        0.725400                0.000000   \n",
            "4         0.0       0.551084        0.725400                0.000000   \n",
            "..        ...            ...             ...                     ...   \n",
            "95        1.0       0.383901        0.517162                0.111927   \n",
            "96        1.0       0.578947        0.000000                0.042202   \n",
            "97        1.0       0.495356        0.863158                0.168807   \n",
            "98        1.0       0.529412        0.826087                0.168807   \n",
            "99        1.0       0.560372        0.588101                0.216514   \n",
            "\n",
            "    Avg_Temp_In_Month  \n",
            "0            0.416961  \n",
            "1            0.674912  \n",
            "2            0.674912  \n",
            "3            0.791519  \n",
            "4            0.791519  \n",
            "..                ...  \n",
            "95           0.628975  \n",
            "96           0.888693  \n",
            "97           0.772085  \n",
            "98           0.772085  \n",
            "99           0.717314  \n",
            "\n",
            "[100 rows x 5 columns]\n",
            "Pre-processed class :\n",
            "[[1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 1.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "filename = \"Updated Fire Data Sample - First 100 Only - Sheet1.csv\"\n",
        "dataset = pd.read_csv(filename)\n",
        "\n",
        "targetFeatures = [\"FIRE_SIZE_CLASS\"]\n",
        "inputFeatures = [\"FIRE_YEAR\", \"DISCOVERY_DOY\", \"DISCOVERY_TIME\", \"Precipitation_In_Month\", \"Avg_Temp_In_Month\"]\n",
        "\n",
        "# Drop NaN values from columns in targetFeatures and inputFeatures\n",
        "dataset.dropna(subset=targetFeatures + inputFeatures, inplace=True)\n",
        "\n",
        "X = dataset[inputFeatures]\n",
        "y = dataset[targetFeatures]\n",
        "\n",
        "# normalize data\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "X_rescaled = scaler.fit_transform(X)\n",
        "X = pd.DataFrame(data = X_rescaled, columns = X.columns)\n",
        "\n",
        "categories = [['A', 'B', 'C', 'D', 'G']]\n",
        "encoder = OneHotEncoder(categories=categories, sparse=False)\n",
        "y = encoder.fit_transform(y.values.reshape(-1,1))\n",
        "\n",
        "print(\"Pre-processed data :\")\n",
        "print(X)\n",
        "\n",
        "print(\"Pre-processed class :\")\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 169,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kuz1ndv2BU00",
        "outputId": "6d3eafdc-fea6-46b5-c15f-16c041a639ef"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0, 0, 1, 0, 0],\n",
              "       [1, 0, 0, 0, 0],\n",
              "       [1, 0, 0, 0, 0],\n",
              "       [1, 0, 0, 0, 0],\n",
              "       [1, 0, 0, 0, 0],\n",
              "       [1, 0, 0, 0, 0],\n",
              "       [1, 0, 0, 0, 0],\n",
              "       [1, 0, 0, 0, 0],\n",
              "       [1, 0, 0, 0, 0],\n",
              "       [1, 1, 0, 0, 0],\n",
              "       [1, 0, 0, 0, 0],\n",
              "       [1, 0, 0, 0, 0],\n",
              "       [1, 0, 0, 0, 0],\n",
              "       [1, 0, 0, 0, 0],\n",
              "       [1, 0, 0, 0, 0],\n",
              "       [1, 0, 0, 0, 0],\n",
              "       [1, 0, 0, 0, 0],\n",
              "       [1, 0, 0, 0, 0],\n",
              "       [1, 0, 0, 0, 0],\n",
              "       [1, 0, 0, 0, 0],\n",
              "       [1, 0, 0, 0, 0],\n",
              "       [1, 0, 0, 0, 0],\n",
              "       [1, 0, 0, 0, 0],\n",
              "       [1, 0, 0, 0, 0],\n",
              "       [1, 0, 0, 0, 0],\n",
              "       [1, 0, 0, 0, 0],\n",
              "       [1, 0, 0, 0, 0],\n",
              "       [1, 0, 0, 0, 0],\n",
              "       [1, 0, 0, 0, 0],\n",
              "       [1, 0, 0, 0, 0]])"
            ]
          },
          "execution_count": 169,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_train, data_test, class_train, class_test = train_test_split(X, y, test_size=0.3)\n",
        "\n",
        "mlp = MLPClassifier(solver = 'sgd', random_state = 42, activation = 'logistic', learning_rate_init = 0.2, batch_size = 10, hidden_layer_sizes = (10, 10), max_iter = 500)\n",
        "\n",
        "mlp.fit(data_train, class_train)\n",
        "\n",
        "pred = mlp.predict(data_test)\n",
        "pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPMsGYmADaIS",
        "outputId": "7b7b3bee-59de-4bbc-af7e-fd1de9feb344"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy :  0.7\n",
            "Mean Square Error :  0.11333333333333333\n",
            "Confusion Matrix for each label : \n",
            "Class: A\n",
            "         Actual Positive | Actual Negative\n",
            "-------------------|-----|----------------\n",
            "Predicted Positive |  22 |   7\n",
            "-------------------|-----|----------------\n",
            "Predicted Negative |   1 |   0\n",
            "TP: 22, FP: 7, FN: 1, TN: 0\n",
            "\n",
            "Class: B\n",
            "         Actual Positive | Actual Negative\n",
            "-------------------|-----|----------------\n",
            "Predicted Positive |   0 |   1\n",
            "-------------------|-----|----------------\n",
            "Predicted Negative |   6 |  23\n",
            "TP: 0, FP: 1, FN: 6, TN: 23\n",
            "\n",
            "Class: C\n",
            "         Actual Positive | Actual Negative\n",
            "-------------------|-----|----------------\n",
            "Predicted Positive |   0 |   1\n",
            "-------------------|-----|----------------\n",
            "Predicted Negative |   1 |  28\n",
            "TP: 0, FP: 1, FN: 1, TN: 28\n",
            "\n",
            "Class: D\n",
            "         Actual Positive | Actual Negative\n",
            "-------------------|-----|----------------\n",
            "Predicted Positive |   0 |   0\n",
            "-------------------|-----|----------------\n",
            "Predicted Negative |   0 |  30\n",
            "TP: 0, FP: 0, FN: 0, TN: 30\n",
            "\n",
            "Class: G\n",
            "         Actual Positive | Actual Negative\n",
            "-------------------|-----|----------------\n",
            "Predicted Positive |   0 |   0\n",
            "-------------------|-----|----------------\n",
            "Predicted Negative |   0 |  30\n",
            "TP: 0, FP: 0, FN: 0, TN: 30\n",
            "\n",
            "Classification Report : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.96      0.85        23\n",
            "           1       0.00      0.00      0.00         6\n",
            "           2       0.00      0.00      0.00         1\n",
            "           3       0.00      0.00      0.00         0\n",
            "           4       0.00      0.00      0.00         0\n",
            "\n",
            "   micro avg       0.71      0.73      0.72        30\n",
            "   macro avg       0.15      0.19      0.17        30\n",
            "weighted avg       0.58      0.73      0.65        30\n",
            " samples avg       0.72      0.73      0.72        30\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "print(\"Accuracy : \", accuracy_score(class_test, pred))\n",
        "print(\"Mean Square Error : \", mean_squared_error(class_test, pred))\n",
        "\n",
        "print(\"Confusion Matrix for each label : \")\n",
        "#print(multilabel_confusion_matrix(class_test, pred))\n",
        "\n",
        "classNum = 0\n",
        "for matrix in multilabel_confusion_matrix(class_test, pred):\n",
        "  print(f\"Class: {categories[0][classNum]}\")\n",
        "  classNum += 1\n",
        "\n",
        "  tn, fp, fn, tp = matrix.ravel()\n",
        "  print(f\"         Actual Positive | Actual Negative\")\n",
        "  print(f\"-------------------|-----|----------------\")\n",
        "  print(f\"Predicted Positive | {str(tp).rjust(3)} | {str(fp).rjust(3)}\")\n",
        "  print(f\"-------------------|-----|----------------\")\n",
        "  print(f\"Predicted Negative | {str(fn).rjust(3)} | {str(tn).rjust(3)}\")\n",
        "  print(f\"TP: {tp}, FP: {fp}, FN: {fn}, TN: {tn}\\n\")\n",
        "\n",
        "print(\"Classification Report : \")\n",
        "print(classification_report(class_test, pred))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
