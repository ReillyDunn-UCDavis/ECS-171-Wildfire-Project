{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "The dataset contains information about the Dollar Damage, Size, Location, and some information about the climate when the fire occured. Because it has information about Dollar Damage, which is what I aim to predict, this will be a supervised model.\n",
        "\n",
        "After doing some data exploration, I found that there is for too much variance in Dollar Damage for any kind of regression model to be reliable. So instead, I have split the costs into classes, similar to how wildfire sizes are split into classes.\n",
        "\n",
        "| Class A | Class B | Class C | Class D  | Class E |\n",
        "|---------|---------|---------|----------|---------|\n",
        "| < \\$100  | \\$100 - \\$500  | \\$500 - \\$2,500 | $2,500 - \\$10,000  | > \\$10,000 |\n",
        "\n",
        "These partitions were chosen so that each class makes up approximately one fifth of the dataset. This was done to prevent any one class from being so common that the model just predicts it every time.\n",
        "\n",
        "With the data split into classes, a Neural Network model can be used to predict which class the fire is likely to be."
      ],
      "metadata": {
        "id": "ON02cBLTrfxw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import classification_report, confusion_matrix, multilabel_confusion_matrix\n",
        "from sklearn.metrics import mean_squared_error, accuracy_score, precision_score, recall_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor"
      ],
      "metadata": {
        "id": "nU9gVtETYjHk"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "Rkvak72rvp54"
      },
      "outputs": [],
      "source": [
        "dataset = pd.read_csv(\"Dollar Damage.csv\")\n",
        "dataset.dropna(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "targetFeatures = [\"Cost Class\"]\n",
        "inputFeatures = [\"Year\", \"Approximate Size (Acres)\", \"Approximate Latitude\", \"Approximate Longitude\", \"Average Temperature In Year In County\", \"Average Precipitation In Year In County\"]\n",
        "\n",
        "X = dataset[inputFeatures]\n",
        "y = dataset[targetFeatures]\n",
        "\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "X_rescaled = scaler.fit_transform(X)\n",
        "X = pd.DataFrame(data = X_rescaled, columns = X.columns)\n",
        "\n",
        "categories = [['A', 'B', 'C', 'D', 'E']]\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(dataset[\"Cost Class\"])\n",
        "\n",
        "print(\"Pre-processed data :\")\n",
        "print(X)\n",
        "\n",
        "print(\"Pre-processed class :\")\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZdvUCQaYKus",
        "outputId": "68d4442b-75e8-4db3-fb53-f9b883f55cb9"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pre-processed data :\n",
            "          Year  Approximate Size (Acres)  Approximate Latitude  \\\n",
            "0     1.000000                       0.0              0.529839   \n",
            "1     1.000000                       0.0              0.621105   \n",
            "2     1.000000                       0.0              0.761188   \n",
            "3     1.000000                       0.0              0.591350   \n",
            "4     1.000000                       0.0              1.000000   \n",
            "...        ...                       ...                   ...   \n",
            "1478  0.083333                       1.0              0.210125   \n",
            "1479  0.083333                       1.0              0.000000   \n",
            "1480  0.083333                       1.0              0.270632   \n",
            "1481  0.083333                       1.0              0.367306   \n",
            "1482  0.083333                       1.0              0.520119   \n",
            "\n",
            "      Approximate Longitude  Average Temperature In Year In County  \\\n",
            "0                  0.259252                               0.575875   \n",
            "1                  0.417000                               0.564202   \n",
            "2                  0.298177                               0.634241   \n",
            "3                  0.428583                               0.583658   \n",
            "4                  0.000000                               0.311284   \n",
            "...                     ...                                    ...   \n",
            "1478               0.977571                               0.785992   \n",
            "1479               0.903008                               0.634241   \n",
            "1480               0.442858                               0.505837   \n",
            "1481               0.651723                               0.307393   \n",
            "1482               0.373262                               0.571984   \n",
            "\n",
            "      Average Precipitation In Year In County  \n",
            "0                                    0.133745  \n",
            "1                                    0.272613  \n",
            "2                                    0.308062  \n",
            "3                                    0.254000  \n",
            "4                                    0.615184  \n",
            "...                                       ...  \n",
            "1478                                 0.065879  \n",
            "1479                                 0.176200  \n",
            "1480                                 0.213950  \n",
            "1481                                 0.302729  \n",
            "1482                                 0.151208  \n",
            "\n",
            "[1483 rows x 6 columns]\n",
            "Pre-processed class :\n",
            "[1 0 0 ... 4 4 4]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyperparameters were chosen after applying the Grid Search Algorithm."
      ],
      "metadata": {
        "id": "MaakAcy6Cn0Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "from sklearn.exceptions import ConvergenceWarning\n",
        "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
        "\n",
        "data_train, data_test, class_train, class_test = train_test_split(X, y, test_size=0.3)\n",
        "\n",
        "mlp = MLPClassifier(solver = 'lbfgs', activation = 'logistic',\n",
        "                    learning_rate_init = 0.2, batch_size = 10, hidden_layer_sizes = (14, 9), max_iter = 200)\n",
        "\n",
        "mlp.fit(data_train, class_train)\n",
        "\n",
        "pred = mlp.predict(data_test)\n",
        "\n",
        "print(\"Accuracy : \", accuracy_score(class_test, pred))\n",
        "print(\"Mean Square Error : \", mean_squared_error(class_test, pred))\n",
        "\n",
        "pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QbJKaoiWNBoc",
        "outputId": "1f7aeaeb-7f26-47c8-fc1e-fbe3ca0504f0"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy :  0.3887640449438202\n",
            "Mean Square Error :  2.1191011235955055\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 4, 2, 0, 1, 2, 4, 4, 4, 2, 0, 4, 4, 2, 2, 4, 4, 0, 4, 0, 2, 1,\n",
              "       0, 0, 2, 0, 2, 0, 2, 0, 4, 2, 4, 0, 4, 4, 0, 0, 2, 0, 4, 1, 4, 2,\n",
              "       4, 0, 1, 1, 2, 2, 0, 1, 0, 4, 1, 0, 4, 1, 0, 2, 2, 4, 2, 1, 2, 4,\n",
              "       4, 2, 4, 0, 4, 1, 4, 4, 2, 0, 0, 0, 2, 1, 4, 0, 0, 0, 0, 4, 4, 2,\n",
              "       4, 4, 4, 2, 0, 0, 0, 2, 1, 0, 0, 1, 0, 1, 4, 1, 0, 0, 1, 0, 2, 0,\n",
              "       0, 1, 2, 0, 4, 2, 1, 4, 1, 2, 2, 4, 0, 4, 2, 0, 0, 2, 2, 2, 2, 0,\n",
              "       4, 0, 0, 4, 3, 4, 4, 0, 1, 0, 3, 0, 0, 3, 4, 4, 0, 0, 1, 0, 4, 0,\n",
              "       0, 4, 0, 4, 0, 0, 1, 2, 0, 4, 1, 0, 3, 4, 2, 0, 0, 2, 2, 1, 0, 4,\n",
              "       2, 1, 2, 4, 0, 4, 2, 1, 3, 4, 2, 4, 4, 4, 0, 4, 1, 4, 0, 0, 0, 2,\n",
              "       0, 2, 2, 2, 4, 1, 0, 2, 4, 0, 1, 1, 4, 4, 0, 4, 2, 4, 4, 1, 1, 0,\n",
              "       0, 0, 2, 4, 4, 1, 0, 0, 4, 0, 0, 1, 2, 0, 4, 0, 2, 4, 3, 2, 0, 4,\n",
              "       1, 1, 2, 4, 4, 4, 2, 4, 1, 4, 2, 0, 2, 0, 0, 4, 1, 0, 1, 0, 0, 0,\n",
              "       0, 0, 2, 0, 1, 1, 3, 4, 4, 2, 0, 2, 2, 4, 4, 0, 3, 0, 2, 0, 4, 0,\n",
              "       4, 3, 2, 4, 4, 4, 4, 0, 4, 2, 0, 4, 0, 0, 4, 2, 0, 2, 0, 4, 0, 0,\n",
              "       1, 2, 4, 1, 4, 1, 0, 2, 0, 3, 0, 4, 2, 0, 0, 4, 4, 1, 4, 1, 0, 4,\n",
              "       4, 4, 0, 2, 4, 0, 0, 4, 2, 3, 1, 1, 4, 4, 1, 1, 0, 0, 0, 2, 4, 4,\n",
              "       2, 0, 0, 4, 0, 4, 0, 1, 1, 0, 2, 2, 1, 2, 4, 2, 4, 0, 4, 1, 0, 4,\n",
              "       0, 4, 1, 2, 2, 1, 4, 0, 4, 4, 2, 2, 2, 4, 4, 4, 0, 3, 3, 1, 2, 0,\n",
              "       0, 1, 0, 4, 1, 2, 0, 4, 4, 4, 4, 4, 4, 4, 0, 2, 2, 0, 0, 1, 0, 2,\n",
              "       0, 4, 4, 0, 2, 0, 0, 4, 0, 2, 4, 1, 2, 4, 2, 0, 2, 1, 4, 2, 0, 0,\n",
              "       1, 1, 0, 2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Confusion Matrix for each label : \")\n",
        "\n",
        "classNum = 0\n",
        "for matrix in multilabel_confusion_matrix(class_test, pred):\n",
        "  print(f\"Class: {categories[0][classNum]}\")\n",
        "  classNum += 1\n",
        "\n",
        "  tn, fp, fn, tp = matrix.ravel()\n",
        "  print(f\"         Actual Positive | Actual Negative\")\n",
        "  print(f\"-------------------|-----|----------------\")\n",
        "  print(f\"Predicted Positive | {str(tp).rjust(3)} | {str(fp).rjust(3)}\")\n",
        "  print(f\"-------------------|-----|----------------\")\n",
        "  print(f\"Predicted Negative | {str(fn).rjust(3)} | {str(tn).rjust(3)}\")\n",
        "  print(f\"TP: {tp}, FP: {fp}, FN: {fn}, TN: {tn}\\n\")\n",
        "\n",
        "print(\"Classification Report : \")\n",
        "print(classification_report(class_test, pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZN5JoOBsNE21",
        "outputId": "9697cb73-3e8b-41cf-8c27-12cd8e00c6d7"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix for each label : \n",
            "Class: A\n",
            "         Actual Positive | Actual Negative\n",
            "-------------------|-----|----------------\n",
            "Predicted Positive |  54 |  88\n",
            "-------------------|-----|----------------\n",
            "Predicted Negative |  45 | 258\n",
            "TP: 54, FP: 88, FN: 45, TN: 258\n",
            "\n",
            "Class: B\n",
            "         Actual Positive | Actual Negative\n",
            "-------------------|-----|----------------\n",
            "Predicted Positive |  20 |  45\n",
            "-------------------|-----|----------------\n",
            "Predicted Negative |  68 | 312\n",
            "TP: 20, FP: 45, FN: 68, TN: 312\n",
            "\n",
            "Class: C\n",
            "         Actual Positive | Actual Negative\n",
            "-------------------|-----|----------------\n",
            "Predicted Positive |  24 |  70\n",
            "-------------------|-----|----------------\n",
            "Predicted Negative |  59 | 292\n",
            "TP: 24, FP: 70, FN: 59, TN: 292\n",
            "\n",
            "Class: D\n",
            "         Actual Positive | Actual Negative\n",
            "-------------------|-----|----------------\n",
            "Predicted Positive |   3 |  10\n",
            "-------------------|-----|----------------\n",
            "Predicted Negative |  74 | 358\n",
            "TP: 3, FP: 10, FN: 74, TN: 358\n",
            "\n",
            "Class: E\n",
            "         Actual Positive | Actual Negative\n",
            "-------------------|-----|----------------\n",
            "Predicted Positive |  72 |  59\n",
            "-------------------|-----|----------------\n",
            "Predicted Negative |  26 | 288\n",
            "TP: 72, FP: 59, FN: 26, TN: 288\n",
            "\n",
            "Classification Report : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.38      0.55      0.45        99\n",
            "           1       0.31      0.23      0.26        88\n",
            "           2       0.26      0.29      0.27        83\n",
            "           3       0.23      0.04      0.07        77\n",
            "           4       0.55      0.73      0.63        98\n",
            "\n",
            "    accuracy                           0.39       445\n",
            "   macro avg       0.34      0.37      0.34       445\n",
            "weighted avg       0.35      0.39      0.35       445\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def gridSearch():\n",
        "  max_iterations = 200 * np.arange(1,3)\n",
        "  hidden_layer_siz = [\n",
        "      (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1),\n",
        "      (10, 2), (11, 2), (12, 2), (13, 2), (14, 2), (15, 2), (16, 2), (17, 2), (18, 2), (19, 2), (20, 2),\n",
        "      (10, 3), (11, 3), (12, 3), (13, 3), (14, 3), (15, 3), (16, 3), (17, 3), (18, 3), (19, 3), (20, 3),\n",
        "      (10, 4), (11, 4), (12, 4), (13, 4), (14, 4), (15, 4), (16, 4), (17, 4), (18, 4), (19, 4), (20, 4),\n",
        "      (10, 5), (11, 5), (12, 5), (13, 5), (14, 5), (15, 5), (16, 5), (17, 5), (18, 5), (19, 5), (20, 5),\n",
        "      (10, 6), (11, 6), (12, 6), (13, 6), (14, 6), (15, 6), (16, 6), (17, 6), (18, 6), (19, 6), (20, 6),\n",
        "      (10, 7), (11, 7), (12, 7), (13, 7), (14, 7), (15, 7), (16, 7), (17, 7), (18, 7), (19, 7), (20, 7),\n",
        "      (10, 8), (11, 8), (12, 8), (13, 8), (14, 8), (15, 8), (16, 8), (17, 8), (18, 8), (19, 8), (20, 8),\n",
        "      (10, 9), (11, 9), (12, 9), (13, 9), (14, 9), (15, 9), (16, 9), (17, 9), (18, 9), (19, 9), (20, 9),\n",
        "      (10, 10), (11, 10), (12, 10), (13, 10), (14, 10), (15, 10), (16, 10), (17, 10), (18, 10), (19, 10), (20, 10)\n",
        "  ]\n",
        "\n",
        "  learning_rates = 0.1 * np.arange(1, 3)\n",
        "\n",
        "  param_grid = dict(learning_rate_init = learning_rates, hidden_layer_sizes = hidden_layer_siz, max_iter = max_iterations)\n",
        "  # set model\n",
        "  mlp = MLPClassifier(solver = 'lbfgs', activation = 'logistic',\n",
        "                      learning_rate_init = 0.2, batch_size = 10, hidden_layer_sizes = (14, 9), max_iter = 200)\n",
        "\n",
        "  # For Grid Search\n",
        "  grid = GridSearchCV(estimator = mlp, param_grid = param_grid)\n",
        "\n",
        "  # For Random Search\n",
        "  # grid = RandomizedSearchCV(estimator = mlp, param_distributions = param_grid, n_iter = 10)\n",
        "\n",
        "  grid.fit(X,y)\n",
        "\n",
        "  print(\"Optimal Hyper-parameters : \", grid.best_params_)\n",
        "  print(\"Optimal Accuracy : \", grid.best_score_)\n",
        "\n",
        "#gridSearch()"
      ],
      "metadata": {
        "id": "Ab0lErcMhSht"
      },
      "execution_count": 57,
      "outputs": []
    }
  ]
}